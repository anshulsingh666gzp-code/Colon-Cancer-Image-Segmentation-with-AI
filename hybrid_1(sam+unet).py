# -*- coding: utf-8 -*-
"""Hybrid 1(Sam+UNet).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1swnfsoY6zOITZs9kDot26XvtCYMD0AaE
"""

# Required libraries for the project
!pip install opencv-python

# Import necessary libraries
import cv2
import numpy as np
import os
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from google.colab import files

from google.colab import files

# Upload the zip file
uploaded = files.upload()

import zipfile
import os

# Unzip the file
zip_file = "Kvasir-SEG.zip"  # Replace with the name of your zip file
destination_dir = "/content/your_folder"  # Replace with the desired destination folder

with zipfile.ZipFile(zip_file, 'r') as zip_ref:
    zip_ref.extractall(destination_dir)

# List the contents of the folder to verify
os.listdir(destination_dir)

# Specify paths to the images and masks
images_path = "/content/your_folder/Kvasir-SEG/images"  # Update with actual path
masks_path = "/content/your_folder/Kvasir-SEG/masks"  # Update with actual path

image_size = (256, 256)  # You can adjust the size

def load_images_and_masks(images_path, masks_path):
    images = []
    masks = []

    # Sort to ensure images and masks are loaded in the correct order
    image_files = sorted(os.listdir(images_path))
    mask_files = sorted(os.listdir(masks_path))

    for img_file, mask_file in zip(image_files, mask_files):
        img_path = os.path.join(images_path, img_file)
        mask_path = os.path.join(masks_path, mask_file)

        # Load the image and mask
        image = cv2.imread(img_path)
        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

        # Resize if necessary
        image = cv2.resize(image, image_size)
        mask = cv2.resize(mask, image_size)

        # Normalize
        image = image / 255.0  # Normalization between 0 and 1
        mask = mask / 255.0  # Masks are also normalized

        images.append(image)
        masks.append(mask)

    # Convert lists to numpy arrays
    return np.array(images), np.array(masks)

# Load images and masks
images, masks = load_images_and_masks(images_path, masks_path)

# Reshape masks to add channel dimension
masks = masks.reshape(*masks.shape, 1)  # Add a channel dimension to the masks

# Print to confirm
print(f"Loaded {len(images)} images and {len(masks)} masks")
print(f"Masks shape: {masks.shape}")  # Print the shape of masks to verify

# Data augmentation parameters
datagen_args = dict(rotation_range=15,
                    width_shift_range=0.1,
                    height_shift_range=0.1,
                    shear_range=0.1,
                    zoom_range=0.1,
                    horizontal_flip=True,
                    fill_mode='nearest')

image_datagen = ImageDataGenerator(**datagen_args)
mask_datagen = ImageDataGenerator(**datagen_args)

# Flow from numpy arrays
image_generator = image_datagen.flow(images, batch_size=32, seed=42)
mask_generator = mask_datagen.flow(masks, batch_size=32, seed=42)

# Combine image and mask generators
train_generator = zip(image_generator, mask_generator)

import tensorflow as tf
from tensorflow.keras import backend as K

# IoU Metric
def iou_metric(y_true, y_pred, smooth=1e-6):
    y_true_f = K.cast(K.flatten(y_true), 'float32')
    y_pred_f = K.cast(K.flatten(y_pred), 'float32')
    intersection = K.sum(y_true_f * y_pred_f)
    union = K.sum(y_true_f) + K.sum(y_pred_f) - intersection
    iou = (intersection + smooth) / (union + smooth)
    return iou

# Dice Coefficient Metric
def dice_coefficient(y_true, y_pred, smooth=1e-6):
    y_true_f = K.cast(K.flatten(y_true), 'float32')
    y_pred_f = K.cast(K.flatten(y_pred), 'float32')
    intersection = K.sum(y_true_f * y_pred_f)
    dice = (2 * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)
    return dice

# Split the data into training and validation sets
x_train, x_val, y_train, y_val = train_test_split(images, masks, test_size=0.2, random_state=42)

# Now you can cast the data types
images = images.astype('float32')
masks = masks.astype('float32')
x_train = x_train.astype('float32')
y_train = y_train.astype('float32')
x_val = x_val.astype('float32')
y_val = y_val.astype('float32')

# Define the integrated hybrid model
def integrated_hybrid_model(input_size=(256, 256, 3)):
    inputs = layers.Input(input_size)

    # UNet Path
    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)
    p1 = layers.MaxPooling2D((2, 2))(c1)

    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)
    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)
    p2 = layers.MaxPooling2D((2, 2))(c2)

    unet_bottleneck = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)

    # SAM Path
    sam_c1 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(inputs)
    sam_p1 = layers.MaxPooling2D((2, 2))(sam_c1)

    sam_c2 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(sam_p1)
    sam_p2 = layers.MaxPooling2D((2, 2))(sam_c2)

    sam_bottleneck = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(sam_p2)

    # Merge Paths
    merged_bottleneck = layers.Concatenate()([unet_bottleneck, sam_bottleneck])

    # Decoder Path
    d1 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(merged_bottleneck)
    d1 = layers.concatenate([d1, c2, sam_c2])
    d1 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(d1)

    d2 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(d1)
    d2 = layers.concatenate([d2, c1, sam_c1])
    d2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(d2)

    # Output Layer
    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(d2)

    # Define Model
    model = models.Model(inputs=[inputs], outputs=[outputs])
    return model

# Create the model
integrated_model = integrated_hybrid_model()

from io import StringIO
from prettytable import PrettyTable

# Capture model summary
summary_buffer = StringIO()
integrated_model.summary(print_fn=lambda x: summary_buffer.write(x + "\n"))

# Parse the summary buffer
summary_lines = summary_buffer.getvalue().strip().split("\n")

# Create PrettyTable with color
table = PrettyTable()
table.field_names = ["Layer Name (type)", "Output Shape", "Param #", "Connected To"]

# Define color codes
HEADER_COLOR = "\033[95m"  # Purple
LAYER_COLOR = "\033[92m"   # Green
PARAM_COLOR = "\033[93m"   # Yellow
CONNECTION_COLOR = "\033[94m"  # Blue
END_COLOR = "\033[0m"      # Reset color

# Parse lines from summary buffer with color formatting
for line in summary_lines:
    if "(" in line and "Layer (type)" not in line and "Param #" not in line:
        # Split the line into parts
        parts = line.split(maxsplit=3)
        layer_name_type = f"{LAYER_COLOR}{parts[0]} {parts[1]}{END_COLOR}"  # Combine layer name and type
        output_shape = parts[2]
        param_count = f"{PARAM_COLOR}{parts[3]}{END_COLOR}"
        connected_to = f"{CONNECTION_COLOR}{parts[4] if len(parts) > 4 else 'N/A'}{END_COLOR}"
        table.add_row([layer_name_type, output_shape, param_count, connected_to])

# Adjust table alignment
table.align["Layer Name (type)"] = "l"  # Left-align layer names
table.align["Output Shape"] = "l"
table.align["Param #"] = "r"
table.align["Connected To"] = "l"

# Print the table with colored headers
print(f"{HEADER_COLOR}Model Summary:{END_COLOR}")
print(table)

# Assuming 'images' and 'masks' are loaded as numpy arrays
# Split the dataset into training and validation sets (80% train, 20% validation)
x_train, x_val, y_train, y_val = train_test_split(images, masks, test_size=0.2, random_state=42)

# Print the shapes to verify
print(f"Training set shape: {x_train.shape}, {y_train.shape}")
print(f"Validation set shape: {x_val.shape}, {y_val.shape}")

def image_mask_generator(images_path, masks_path, batch_size, image_size=(256, 256)):
    image_files = sorted(os.listdir(images_path))
    mask_files = sorted(os.listdir(masks_path))

    while True:
        batch_images = []
        batch_masks = []

        for i in range(batch_size):
            idx = np.random.randint(0, len(image_files))  # Randomly select an index

            # Load images and masks
            img_path = os.path.join(images_path, image_files[idx])
            mask_path = os.path.join(masks_path, mask_files[idx])

            image = cv2.imread(img_path)
            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

            # Resize images and masks
            image = cv2.resize(image, image_size)
            mask = cv2.resize(mask, image_size)

            # Normalize image and mask
            image = image / 255.0
            mask = mask / 255.0

            batch_images.append(image)
            batch_masks.append(np.expand_dims(mask, axis=-1))  # Add an extra dimension for the mask

        yield np.array(batch_images), np.array(batch_masks)

# Set the batch size
batch_size = 16

# Define train generator
train_generator = image_mask_generator(images_path, masks_path, batch_size)

# Compile the model with additional metrics
integrated_model.compile(optimizer='adam',
                         loss='binary_crossentropy',
                         metrics=['accuracy', iou_metric, dice_coefficient])

# Train the model
history = integrated_model.fit(train_generator,
                                steps_per_epoch=len(x_train) // batch_size,
                                epochs=50,
                                validation_data=(x_val, y_val))  # Validation data as numpy arrays

# Save the trained model
integrated_model.save('kvasir_colon_cancer_segmentation_unet.h5')

# Evaluate the model and print all metrics including IoU and Dice coefficient
loss, accuracy, iou, dice = integrated_model.evaluate(x_val, y_val)
print(f"Validation Loss: {loss}")
print(f"Validation Accuracy: {accuracy}")
print(f"Validation IoU: {iou}")
print(f"Validation Dice Coefficient: {dice}")

# Predict on validation data
preds = integrated_model.predict(x_val)

# Visualization function
def visualize_result(image, mask, prediction):
    plt.figure(figsize=(10, 5))

    # Display the original image
    plt.subplot(1, 3, 1)
    plt.imshow(image)
    plt.title("Original Image")

    # Display the ground truth mask
    plt.subplot(1, 3, 2)
    plt.imshow(mask[:, :, 0], cmap='gray')
    plt.title("True Mask")

    # Display the predicted mask
    plt.subplot(1, 3, 3)
    plt.imshow(prediction[:, :, 0], cmap='gray')
    plt.title("Predicted Mask")

    plt.show()

# Visualize the first result
visualize_result(x_val[0], y_val[0], preds[0])

# Refined post-processing function with Gaussian blur and thresholding
def post_process(prediction, threshold=0.3, kernel_size=5):
    """
    Apply Gaussian smoothing and thresholding to improve the predicted mask quality.
    """
    # Apply Gaussian blur to smooth the prediction mask
    smoothed_prediction = cv2.GaussianBlur(prediction, (kernel_size, kernel_size), 0)
    # Apply thresholding
    binary_mask = (smoothed_prediction > threshold).astype(np.uint8)

    return smoothed_prediction, binary_mask

# Post-process and visualize each step for clarity
smoothed_mask, binary_mask = post_process(preds[0][:, :, 0])  # Pass only the first channel

# Visualization function to see each step
def visualize_intermediate_steps(image, mask, raw_prediction, smoothed_prediction, binary_prediction):
    plt.figure(figsize=(15, 5))

    # Original image
    plt.subplot(1, 5, 1)
    plt.imshow(image)
    plt.title("Original Image")

    # Ground truth mask
    plt.subplot(1, 5, 2)
    plt.imshow(mask[:, :, 0], cmap='gray')
    plt.title("True Mask")

    # Raw predicted mask
    plt.subplot(1, 5, 3)
    plt.imshow(raw_prediction[:, :, 0], cmap='gray')
    plt.title("Predicted Mask (Raw)")

    # Smoothed prediction (2D array)
    plt.subplot(1, 5, 4)
    plt.imshow(smoothed_prediction, cmap='gray')
    plt.title("Smoothed Prediction")

    # Final binary mask (post-processed, 2D array)
    plt.subplot(1, 5, 5)
    plt.imshow(binary_prediction, cmap='gray')
    plt.title("Binary Mask (Post-Processed)")

    plt.show()

# Visualize with intermediate steps
visualize_intermediate_steps(x_val[0], y_val[0], preds[0], smoothed_mask, binary_mask)

